{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4pVVacFjNSw"
      },
      "source": [
        "# Challenge: Generative AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB-UQJk8jNSx"
      },
      "source": [
        "In this challenge, three generative models are provided.\n",
        "\n",
        "For each generative model, you are tasked with answering two questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxNBKu9jNSx"
      },
      "source": [
        "## 0. Preconfiguration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lEl42sGjNSy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRiXw2GKjNSy"
      },
      "source": [
        "If you use Google Colab and the above code returns False, click on `Runtime`, `Change runtime type`, and choose `T4 GPU`. Then run the notebook again from the start."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We install the required libaries."
      ],
      "metadata": {
        "id": "eEParobUljis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade diffusers accelerate mediapy"
      ],
      "metadata": {
        "id": "FDKv-GMtlh3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSQj1TSBjNSy"
      },
      "source": [
        "We import useful libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEczAsoEjNSy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributions as D\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import sklearn.datasets\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import imageio.v3 as iio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqAKmyPjNSy"
      },
      "source": [
        "### Dataset visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKYboicDjNSz"
      },
      "source": [
        "We use the dataset \"Labeled Faces in the Wild\", which contains more than 13,000 images of faces collected from the web.\n",
        "\n",
        "We resize them to 36 x 28 to improve the training speed of the models.\n",
        "\n",
        "The images are composed of 3 channels for the RGB color model, as opposed to 1 channel in MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi326598jNSz"
      },
      "outputs": [],
      "source": [
        "data = sklearn.datasets.fetch_lfw_people(resize=0.3, color=True, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True, return_X_y=False)\n",
        "dataset = data['images'].transpose(0, 3, 1, 2)\n",
        "transform = transforms.Resize((36, 28), Image.BICUBIC, antialias=True)\n",
        "dataset = transform(torch.tensor(dataset))\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzevG6ktjNSz"
      },
      "source": [
        "We define hyperparameters for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scEpfXDejNSz"
      },
      "outputs": [],
      "source": [
        "size, n_channels, height, width = dataset.shape\n",
        "X_dim = n_channels * height * width\n",
        "\n",
        "batch_size = 128\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86T8tZV5jNSz"
      },
      "outputs": [],
      "source": [
        "train_set = dataset\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaoEh_CfjNSz"
      },
      "source": [
        "We plot a few images of the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt2t0fOIjNSz"
      },
      "outputs": [],
      "source": [
        "def plot_images(images, ncols=8):\n",
        "    grid = torchvision.utils.make_grid(images, nrow=ncols)\n",
        "    # In `make_grid`, `nrow` is a misnomer and represents the number of columns.\n",
        "    fig, axis = plt.subplots(dpi=150)\n",
        "    axis.imshow(grid.permute(1, 2, 0), vmin=0, vmax=1)\n",
        "    axis.axis('off')\n",
        "\n",
        "rgb_images = next(iter(train_loader))[:32]\n",
        "plot_images(rgb_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ6yhuoYjNSz"
      },
      "source": [
        "## 1. Multivariate Gaussian distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbFHjgNWjNSz"
      },
      "source": [
        "We define hyperparameters for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx2F3YhEjNSz"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "nb_epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwsN5JXmjNSz"
      },
      "source": [
        "We define a baseline module for estimating the parameters of a multivariate Gaussian distribution with diagonal covariance matrix.\n",
        "The dimension of this distribution is 3 * 36 * 28, which corresponds to the dimension of an image.\n",
        "\n",
        "Since the covariance matrix is diagonal, there will be no dependence between the different dimensions of the image.\n",
        "In other words, the model will naively fit a distribution independently for each pixel of the image.\n",
        "Thus, we expect this model to have poor sample quality and diversity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6noADLGajNS0"
      },
      "outputs": [],
      "source": [
        "class DiagonalGaussianModule(torch.nn.Module):\n",
        "    def __init__(self, d):\n",
        "        super().__init__()\n",
        "        self.mean = torch.nn.Parameter(torch.randn(d))\n",
        "        self.rho = torch.nn.Parameter(torch.randn(d))\n",
        "\n",
        "    def dist(self):\n",
        "        stddev = torch.nn.Softplus()(self.rho) + 1e-5\n",
        "        return D.Independent(D.Normal(self.mean, stddev), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeRubB8IjNS0"
      },
      "source": [
        "Similarly to Lab 1, we perform gradient descent with maximum likelihood estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx6JgqQ0jNS0"
      },
      "outputs": [],
      "source": [
        "module = DiagonalGaussianModule(X_dim)\n",
        "\n",
        "def train(train_loader, lr, nb_epochs):\n",
        "    loss_list = []\n",
        "\n",
        "    optimizer = torch.optim.Adam(module.parameters(), lr=lr)\n",
        "    for epoch in range(nb_epochs):\n",
        "        for x in train_loader:\n",
        "            x = x.view(-1, X_dim).float()\n",
        "            optimizer.zero_grad()\n",
        "            dist = module.dist()\n",
        "            # We compute the negative log-likelihood of the samples\n",
        "            loss = -dist.log_prob(x).mean()\n",
        "            # We compute the gradients\n",
        "            loss.backward()\n",
        "            # We modify the parameters using gradient descent\n",
        "            optimizer.step()\n",
        "            loss_list.append(loss.item())\n",
        "    return loss_list\n",
        "\n",
        "loss_list = train(train_loader, lr=lr, nb_epochs=nb_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvFgG4gejNS0"
      },
      "source": [
        "We plot the loss per step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpgG9sTZjNS0"
      },
      "source": [
        "**Q1.1: What can you conclude based on the training curve?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J8di9K8jNS0"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgLVPvZ9jNS0"
      },
      "source": [
        "We plot different samples of the distribution. As you can see, there is a lot of noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKDQmK94jNS0"
      },
      "source": [
        "**Q1.2: Which hyperparameters could you modify to improve the quality of the samples? Can you discuss the effect of each of them?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRKwyBbrjNS0"
      },
      "outputs": [],
      "source": [
        "sample = module.dist().sample((32,)).detach()\n",
        "sample = sample.reshape(-1, n_channels, height, width)\n",
        "plot_images(sample)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOrZLjFLjNS0"
      },
      "source": [
        "## 2. Variational auto-encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6C-cXffjNS0"
      },
      "source": [
        "Similarly to Lab 2, we define a varitional auto-encoder (VAE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQmZR6fcjNS0"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, H_dim, Z_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(X_dim, H_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(H_dim, 2 * Z_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (x - 0.5) * 2\n",
        "        mu, rho = torch.chunk(self.model(x), 2, dim=1)\n",
        "        std = F.softplus(rho)\n",
        "        return D.Independent(D.Normal(mu, std), 1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, H_dim, Z_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(Z_dim, H_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(H_dim, X_dim),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Unflatten(1, (n_channels, height, width)),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        means = self.model(z)\n",
        "        return D.Independent(D.Normal(means, torch.ones_like(means)), 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aISogXaAjNS1"
      },
      "source": [
        "We define hyperparameters for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-b6J_myjNS1"
      },
      "outputs": [],
      "source": [
        "H_dim = 15\n",
        "Z_dim = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLmGp_uNjNS1"
      },
      "source": [
        "We instantiate the encoder and decoder and count the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKYqqBHyjNS1"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(H_dim, Z_dim).to(device)\n",
        "decoder = Decoder(H_dim, Z_dim).to(device)\n",
        "\n",
        "def params_count(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print('Total parameters of the encoder:', params_count(encoder))\n",
        "print('Total parameters of the decoder:', params_count(decoder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1372zw5jNS1"
      },
      "source": [
        "The prior distribution is a standard normal distribution over the latent space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBCPIflWjNS1"
      },
      "outputs": [],
      "source": [
        "prior = D.Independent(D.Normal(torch.zeros(Z_dim).to(device), torch.ones(Z_dim).to(device)), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf4bLjGnjNS1"
      },
      "source": [
        "The training loop based on gradient descent is defined here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOWPN7uQjNS1"
      },
      "outputs": [],
      "source": [
        "def train(encoder, decoder, train_loader, num_epochs, lr=1e-3):\n",
        "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
        "    step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for x in train_loader:\n",
        "            x = x.to(device).float()\n",
        "            # ===== Forward pass =====\n",
        "            z_dist = encoder(x)\n",
        "            z = z_dist.rsample()\n",
        "            x_dist = decoder(z)\n",
        "            # ===== Loss =====\n",
        "            reconstruction_loss = -x_dist.log_prob(x).mean()\n",
        "            complexity_loss = D.kl_divergence(z_dist, prior).mean()\n",
        "            loss = reconstruction_loss + complexity_loss\n",
        "            # ===== Backward pass =====\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # ===== Logging =====\n",
        "            if step % 100 == 0:\n",
        "                print(f'epoch [{epoch + 1}/{num_epochs}], step {step + 1}, loss:{loss.item():.4f}')\n",
        "            step += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-z1G6U2jNS1"
      },
      "source": [
        "To avoid waiting, if you already trained a model, you can skip this cell and load a pre-trained model using the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xJZTfWSjNS1"
      },
      "outputs": [],
      "source": [
        "train(encoder, decoder, train_loader, 10, lr=1e-3)\n",
        "\n",
        "# Save the model parameters.\n",
        "torch.save(encoder.state_dict(), 'encoder.pth')\n",
        "torch.save(decoder.state_dict(), 'decoder.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXlHuNJrjNS1"
      },
      "source": [
        "Running this cell will load the last model that has been trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38jdKJq1jNS1"
      },
      "outputs": [],
      "source": [
        "encoder.load_state_dict(torch.load('encoder.pth'))\n",
        "decoder.load_state_dict(torch.load('decoder.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkbPghBujNS2"
      },
      "source": [
        "We sample new data points using our trained model.\n",
        "\n",
        "**Q2.1: Can you experiment with the hyperparameters of this model to improve the quality of the generation?**\n",
        "\n",
        "You will be able to improve the quality of the samples.\n",
        "However, keep in mind that, with the current architecture, you will not be able to reach high levels of realism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XkrLlYejNS2"
      },
      "source": [
        "**Q2.2: Can you compare the quality of the generations of the VAE with your best model from Section 1?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzTb2jJ-jNS2"
      },
      "outputs": [],
      "source": [
        "z = prior.sample((32,))\n",
        "with torch.no_grad():\n",
        "    sample = decoder(z).mode\n",
        "plot_images(sample.cpu())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwsHA_TUjNS2"
      },
      "source": [
        "## 3. Diffusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r06MecBCjNS2"
      },
      "source": [
        "We define the hyperparameters of the diffusion model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf_QDfVujNS2"
      },
      "outputs": [],
      "source": [
        "n_epoch = 5\n",
        "lrate = 1e-3\n",
        "n_T = 400\n",
        "\n",
        "results_dir = Path('results')\n",
        "results_dir.mkdir(exist_ok=True)\n",
        "checkpoint_dir = Path('checkpoints')\n",
        "checkpoint_dir.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en_QPcAVjNS2"
      },
      "source": [
        "Similarly to Lab 3, we define a UNet and a diffusion model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ubA0KBLjNS2"
      },
      "outputs": [],
      "source": [
        "from diffusers import UNet2DModel\n",
        "\n",
        "def create_unet():\n",
        "    return UNet2DModel(\n",
        "        sample_size=(height, width),\n",
        "        in_channels=3,\n",
        "        out_channels=3,\n",
        "        layers_per_block=2,\n",
        "        block_out_channels=(128, 256, 384),\n",
        "        down_block_types=('DownBlock2D', 'AttnDownBlock2D', 'AttnDownBlock2D'),\n",
        "        up_block_types=('AttnUpBlock2D', 'AttnUpBlock2D', 'UpBlock2D'),\n",
        "    )\n",
        "\n",
        "unet = create_unet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pzyld1CjNS2"
      },
      "outputs": [],
      "source": [
        "#@title DDPM schedules\n",
        "\n",
        "def ddpm_schedules(beta1: float, beta2: float, T: int):\n",
        "    \"\"\"\n",
        "    Returns pre-computed schedules for DDPM sampling and training process.\n",
        "    \"\"\"\n",
        "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
        "\n",
        "    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
        "    sqrt_beta_t = torch.sqrt(beta_t)\n",
        "    alpha_t = 1 - beta_t\n",
        "    log_alpha_t = torch.log(alpha_t)\n",
        "    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
        "\n",
        "    sqrtab = torch.sqrt(alphabar_t)\n",
        "    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
        "\n",
        "    sqrtmab = torch.sqrt(1 - alphabar_t)\n",
        "    mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
        "\n",
        "    return {\n",
        "        \"alpha_t\": alpha_t,  # \\alpha_t\n",
        "        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
        "        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
        "        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
        "        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
        "        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
        "        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeVchGPyjNS2"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(self, eps_model, betas, n_T):\n",
        "        super().__init__()\n",
        "        self.eps_model = eps_model\n",
        "        self.n_T = n_T\n",
        "\n",
        "        # We store values of the schedule here.\n",
        "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
        "            self.register_buffer(k, v)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        t = torch.randint(1, self.n_T + 1, (x.shape[0],)).to(x.device) # Random time step\n",
        "        noise = torch.randn_like(x) # Noise\n",
        "        # We apply noise to the input\n",
        "        x_t = (\n",
        "            self.sqrtab[t, None, None, None] * x\n",
        "            + self.sqrtmab[t, None, None, None] * noise\n",
        "        )\n",
        "        # We predict the noise that was applied to the input\n",
        "        pred = self.eps_model(x_t, t / self.n_T)['sample']\n",
        "        # The loss is defined here\n",
        "        return nn.MSELoss()(noise, pred)\n",
        "\n",
        "    def sample(self, n_sample, size, device, save_interval=20) -> torch.Tensor:\n",
        "        x = torch.randn(n_sample, *size).to(device) # Initial noisy image\n",
        "\n",
        "        x_per_step = [] # We will save the intermediate results here\n",
        "        for i in tqdm(range(self.n_T, 0, -1)): # We go backwards in the diffusion process\n",
        "            t = torch.tensor([i / self.n_T]).to(device) # Current time step\n",
        "            t = t.repeat(n_sample) # We repeat the time step for each image in the batch\n",
        "\n",
        "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
        "            eps = self.eps_model(x, t)['sample'] # We predict the noise\n",
        "            x = ( # We denoise the image\n",
        "                self.oneover_sqrta[i] * (x - eps * self.mab_over_sqrtmab[i])\n",
        "                + self.sqrt_beta_t[i] * z\n",
        "            )\n",
        "            if i % save_interval == 1:\n",
        "                x_per_step.append(x)\n",
        "\n",
        "        return x, torch.stack(x_per_step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLm1MwvLjNS2"
      },
      "source": [
        "We also define utility functions to plot images and gifs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlBTGXDqjNS3"
      },
      "outputs": [],
      "source": [
        "#@ Utility functions for plotting\n",
        "\n",
        "def create_gif(sample_per_step, epoch):\n",
        "    frames = []\n",
        "    for sample in sample_per_step:\n",
        "        frame = torchvision.utils.make_grid(sample, nrow=16)\n",
        "        #frame = frame.clamp(0, 1)\n",
        "        frames.append(frame)\n",
        "    frames = torch.stack(frames).permute(0, 2, 3, 1).numpy()\n",
        "    frames = (frames * 255).astype(np.uint8)\n",
        "    iio.imwrite(results_dir / f'sample_diffusion_epoch_{epoch}.gif', frames, duration=100)\n",
        "\n",
        "\n",
        "def save_samples(ddpm, epoch):\n",
        "    with torch.no_grad():\n",
        "        sample, sample_per_step = ddpm.sample(32, (n_channels, height, width), device)\n",
        "    sample = sample.cpu()\n",
        "    sample_per_step = sample_per_step.cpu()\n",
        "    # Rescale the images to [0, 1]\n",
        "    sample = (sample + 1) / 2\n",
        "    sample_per_step = (sample_per_step + 1) / 2\n",
        "\n",
        "    fig = plot_images(sample)\n",
        "    plt.savefig(results_dir / f'sample_epoch_{epoch}.png')\n",
        "    plt.close(fig)\n",
        "\n",
        "    create_gif(sample_per_step, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1riPv-04jNS3"
      },
      "source": [
        "We perform gradient descent to optimize the parameters of the UNet.\n",
        "\n",
        "Note that training a diffusion model can take a long time. For example, training Stable Diffusion would take more than 20,000 hours with an RTX A100, one of the best available GPUs.\n",
        "\n",
        "In our case, training a good model could take one hour or more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04upSR4mjNS3"
      },
      "source": [
        "**Q3.1: Can you experiment with the hyperparameters of this model to improve the quality of the generation? The loss should converge towards 0. Discuss the results that you obtain with different hyperparameters.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rL08FpFjNS3"
      },
      "source": [
        "**Q3.2: Can you compare the quality of the generations of the diffusion model with your best model from Section 2?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaSDe0nCjNS3"
      },
      "outputs": [],
      "source": [
        "ddpm = DDPM(eps_model=unet, betas=(1e-4, 0.02), n_T=n_T).to(device)\n",
        "optim = torch.optim.Adam(ddpm.parameters(), lr=lrate)\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    print(f'Epoch {epoch}')\n",
        "    ddpm.train()\n",
        "\n",
        "    # Linear learning rate decay\n",
        "    optim.param_groups[0]['lr'] = lrate * (1 - epoch / n_epoch)\n",
        "\n",
        "    pbar = tqdm(train_loader)\n",
        "    for x in pbar:\n",
        "        optim.zero_grad()\n",
        "        x = x.to(device)\n",
        "        x = x * 2 - 1 # Rescale to [-1, 1]\n",
        "        loss = ddpm(x)\n",
        "        loss.backward()\n",
        "        pbar.set_description(f'Loss: {loss:.4f}')\n",
        "        optim.step()\n",
        "\n",
        "    ddpm.eval()\n",
        "    if epoch % 2 == 0 or epoch == int(n_epoch - 1):\n",
        "        save_samples(ddpm, epoch) # Save images and gifs\n",
        "    if epoch % 50 == 0 or epoch == int(n_epoch - 1): # Save checkpoints\n",
        "        torch.save(ddpm.state_dict(), checkpoint_dir / f'model_{epoch}.pth')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}